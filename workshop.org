#+SEQ_TODO: TODO | DONE

* glossary
- package
- project
- analysis
- virtual environement
* Introduction
  What we are concerned about today: the problem(s) we want to solve.
  What we are going to do, the tools that we are going to use.
  The example that we are going to consider.

* Part 1 - Making a package
** Initial motivation: separating methods from parameters and data
A numerical experiment has three components:
- The data (dataset, or parameters of simulation)
- The operations performed on this data
- The output (numbers, plots)

At the moment parameters (input data), operations and output are intertwined in a single
python script.

This is often what we do in early exploratory phases, when the objective is to get insight
into data quickly. /Quickly/ means without having to think about software, /i.e/ taking the
shortest path to the scientific output (the plot).

However, this approach is (by design) messy.
Depsite short term convenience, putting data, operations and output in the same file is very
likely to slow down your research process on a longer term.

The main reason is code-reuse. Consider the situation where you have a similar timeseries,
and want to visualise its histogram. A straightfoward solution would be to copy and paste
lines 19 to 30 to the anaylis program for the new timeseries.
This approach is risky:
- If you want to modify this portion of code (fixing a bug, making improvements) you have to
  make sure you do across all the places where you duplicated the code.
- The duplicated code may not integrate itself well in another programm (conflicts in variable
names for example.
- Coding style discrepancies leading to poor readability.

Instead, we are going to separate the /operations/ from the data and output.
More precisely, we are going to implement the /operations/ on data inside a specific
/package/ that we trust and can reuse across many similar analyses.

The result could look like this:
#+begin_src python
  import numpy as np
  import matplotlib.pyplot as plt
  import my_pkg

  timeseries = np.genfromtxt("./data/my_timeseries.csv", delimiter=",")

  mean, var = my_pkg.get_mean_and_var(timeseries)

  fig, ax = my_pkg.get_pdf(timeseries)

  threshold = 3*np.sqrt(var)
  fig, ax = my_pkg.show_extremes(timeseries, threshold)
#+end_src

The above script is much shorter and easier to read, because the actual implementation of
the various operations (computing the mean and variance, computing the histogram...) is now
/encpsulated/ inside the package ~my_pkg~. All that remains are the actual steps of the
analysis.

If we were to make changes to the way some operations are implemented, we could simply make
changes to the package, leaving the scripts unmodified. The changes are then made avaialble
to all the programs that use the package: no more copying and pasting code around.

Conversely, by making change to the operations, you are a no risk of modyfing the analysis
itself (sequence of operations, data and parameters, output).

Taking a step back, the idea of separating different components is pervasive in software developemt
and software design. Different names depending on the field (encapsulation, separation of concerns,
bounded contexts...).

** Making a python package
*** The python hierachy: objects, modules, packages
- functions, classes
#+begin_src python
  # operations.py
  def add(a,b):
      return a+b
#+end_src
- modules
  Collection of python objects (classes, functions, variables)
#+begin_src python
  from operations import add
  # "From file (or module) operations.py import object add"

  result = add(1,2)
#+end_src
- packages
  Collection of modules (~.py~ files)
  #+begin_src python
    from calculator.operations import add
    from calculator.representations import hexa

    a = hexa(1)
    b = hexa(2)

    result = add(a,b)
  #+end_src

**** EXERCISE 1. Rewrite scripts into collection of functions
 Let's rewrite both scripts ~analyse_timeseries.py~ and ~show_extremes.py~
 as a collection of functions that can be reused in separate scripts.

 The directory ~tstools/~ contains 3 python modules that
 contain (incomplete) functions performing the operations on data described in the original scripts
 ~analysis_timeseries.py~ and ~show_extremes.py~

 1. Open ~tstools/moments.py~ and complete function ~get_mean_and_var~ (replace the
    string ~"######"~).
 2. Open file ~tstools/vis.py~ and complete functions ~plot_trajectory_subset~ and
    ~plot_histogram~ (replace the strings ~"######"~).

 File ~tstools/extremes.py~ implements a function ~show_extremes~ corresponding to script ~show_extremes.py~.
 It is already complete.
 So now it is technically possible to import each functions from the modules.
 But the script must be in this directory next to the modules.
 Plus we want to bundle both modules (and the ones to come) into a coherent
 ensemble: a /package/.

*** Let's make a package out of our 2 scripts
We now have a ~tstools~ directory with 3 modules:
#+begin_example
  analysis1/
	  tstools/
		  __init__.py
		  moments.py
		  vis.py
		  show_extremes.py
	  data/
#+end_example

In way, the directory ~tstools~ is already a pacakge, in the sens that it is possible to import each functions from the modules:
#+begin_src python
import tstools.moments
from tstools.vis import plot_histogram

timeseries = np.genfromtxt("../../data/brownian.csv", delimiter=",")

mean = tstools.moments.get_mean(timeseries)
fig, ax = tstools.moments.plot_histogram(timeseries)
#+end_src

Note that src_python{import tstools} doesn't actually import anything!

*** init dot pie
Let's try to import the package as a whole:
#+begin_src python
import tstools
timeseries = np.genfromtxt("../../data/brownian.csv", delimiter=",")
mean = tstools.moments.get_mean(timeseries)
#+end_src

#+begin_example
Error because nothing was imported
#+end_example

What happened here? When importing the directory ~tstools~, the python interpreter
looks for a file named ~__init__.py~ inside this directory and imports this python file.
If this python file is empty, or simply doesnt exists... nothing is imported.

For example, let's add a simple ~print~ statement to the ~__init__.py~ and import
function ~get_mean_and_var~ from module ~tstools.py~:
#+begin_src python
filename = __file__
print(f"Hello from {filename}")
#+end_src

Any object (variable, function, class) defined in the ~__inint__.py~ file is available
under the paakge's namspace:

#+begin_src python
  import tstools
  print(tstools.filename)
#+end_src

Our pacakge isn't very big, and the internal strucure with 3 different modules isnt
very relevant for a user.
Instead of ~mean, var = tstools.moments.get_mean(timseries)~ we would prefer, ~tstools.get_mean(timeseries)~.

#+begin_exercise
Write the ~__init__.py~ so that all functions defined in
modules ~tstools.py~ and ~show_extremes.py~ are accessible directly
at the top-lvel (under the ~tstools~ namespace), /i.e/

#+begin_src python
  import tstools
  meab, var = tstools.get_mean_and_var
  fig, ax = tstools.show_extremes(timeseries, 4*np.sqrt(var))
#+end_src

Hint: By default python looks for modules in the current directory
and some other locations (more about that later). When using ~import~,
you can refer to modules in the current package using the /dot notation/:
#+begin_src python
  # import something from module that resides
  # in the current package (next to the __init__.py)
  from .module import something
#+end_src
#+end_exercise

Our package is ready to be used!

#+begin_src python
  # In directory python-packaging-workshop/
  import numpy as np
  import matplotlib.pyplot as plt
  import tstools

  timeseries = np.genfromtxt("./data/my_timeseries.csv", delimiter=",")

  mean, var = tstools.get_mean_and_var(timeseries)

  fig, ax = tstools.get_pdf(timeseries)

  threshold = 3*np.sqrt(var)
  fig, ax = tstools.show_extremes(timeseries, threshold)
#+end_src

*** TODO Whats the value of any empty ~__init__.py~ ?
*** Note: objets defined in __init__.py are avaialbe when importing /the pacakge/
#+begin_src python
    # __init__.py
    mysymbol = "something"
    print(mysymbol)
#+end_src

#+begin_src python
  from tstools.tstools import get_mean_and_var
  # this prints "something" but mysymbol is not
  # accessible from tstools' namespace
#+end_src
* Part 2 - using the package across analyses
Let's say that we have another directory ~analysis2~, that contains another
but similar dataset to ~analysis1~.
Now that we've separated structured our software into a python package, we would like
to reuse that package for our second analysis.

Let us simply write a python scripts ~analysis2.py~, that imports the ~tstools~ package
created in the previous section.
#+begin_example
  analysis2/
	  analysis2.py
	  data/
		  timeseries.csv
#+end_example

#+begin_src python
  # analysis2.py
  import numpy as np
  import tstools

  timeseries = np.genfromtxt("./data/data.csv")
  fig, ax = tstools.plot_trajectory_subset(timeseries, 0, 50, dt=0.1)
#+end_src

Unfortunately, Python cannot find the package (which at the moment lives in the directory ~analysis1/~).

** Where does python look for packages?
When using the ~import~ statement, the python interpreter looks for the package (or module) in a list of directories
known as the /python path/.

We can find out about what directories constitute the python path:

#+begin_example
>>> import sys
>>> sys.path
#+end_example

The order of this list is important: python first looks inside the current directory.

If the package/module is not found in the current directory, Python looks for it in the following directories
- ~/usr/lib/python38.zip~
- ~/usr/lib/python3.8~
- ~/usr/lib/python3.8/lib-dynload~
The above contain the modules and packages in the /standard library/, /i.e/ the packages and modules that
come "pre-installed" with Python.

Finally, the python interpreter looks inside the directory ~python-workshop/lib/python3.8/site-packages/~.


For Python to find out package ~tstools~ it must be located in one of the directories listed in
the ~sys.path~ list. If it is the case, the package is said to be /installed/.

Potential solutions:
1. *Copy package directory (~analysis1/tstools/~) in the current analysis directory (~analysis2/~)*.
  You end up with two independant packages. If you make changes to one, you have to remember to make the same
  changes to the other. It's the usual copy and paste problems: inefficient and error-prone.
2. *Add ~analysis1/pkg~ to ~sys.path~*.
  At the beginning of your script, you could just
#+begin_src python
  import sys
  sys.path.append("../analysis1/")
#+end_src
This approach can be sufficient in some situations, but generally not recommended. What if the package directory is relocated?
3. *Copy ~analysis1/tstools~ dir to ~site-packages~ dir.*
  You have to know where the ~site-packages~ is. This depends on your current system and python environment (see below).
  The location on your macine may very well be differnt from the location on your colleague's machine.

Generally, the three approaches above overlook a very important point: *dependencies*.
Our package has two: numpy and matplotlib.
If you were to give your package to a colleague, nothing garantees that they have both packages installed.
This is a pedagogical example. In a real case scenario, it is likely that they would have both installed, are they are widely used.
However, if your package relies on less used packages, or specific versions of them, it is important to make sure that they
are available.

Note that all three above approaches work. However, unless you have a good reason to use one of them, they are not recommended.

** setuptools and setup dot pie
The recommended way to install a package is to use the ~setuptools~ library in conjunction with
~pip~, the official python /package manager/.

In effect, this approach is roughly equivalent to appraoch number (3) described in the previous section.
However, the installation is *automated*.

*** setup dot pie and distribution packages
Installing a package with ~pip~ looks like this
#+begin_src shell
pip install <package directory>
#+end_src

let's give it a try
#+begin_src shell
# In directory analysis1/
pip install tstools
#+end_src

#+begin_example
Error because no setup.py
#+end_example

For ~pip~ to be able to install our package, we must first give it some information about it.
In fact ~pip~ expects to find a python file named ~setup.py~ in the directory that it is
given as an argument. This file is expected to call the function ~setup~
provided by the ~setuptools~ package (or the deprecated ~distutils~ package).


Here is a minimal ~setup.py~ file
#+begin_src python
  # In directory tstools-proj
  from setuptools import setup

  setup(name='tstools',
	version='0.1',
	description='A package to analyse timeseries',
	url='',
	author='Spam Eggs',
	package=['tstools'],
	license='GPLv3')
#+end_src

The above gives ~pip~ some metadata about our package and, more importantly, the location
of the package to be install, in this case the directory ~tstools~.

*IMPORTANT*: The above ~setup.py~ states \src_python{(...,package=["tstools"],...)}. In English, this means:
"setuptools, please install the package ~tstools/~ located in the same directory as the file ~setup.py~".
this means that the file ~setup.py~ resides in the directory that contains the package, in this case ~analysis1/~.

Actually, there are no reasons why our ~tstools~ package should be located in the ~analysis1/~ directory.
Indeed, the package is independant from it and we aim at reusing it across multiple analyses.
To reflect this, let's move the ~tstools~ package into a new directory ~tstools-dist~ located next to the ~anaylis1~ and
~analysis2~ directories:

#+begin_example
  python-workshop/
	  analysis1/
		  data/
		  analysis1.py
	  analysis2/
		  data/
		  analysis2.py
	  tsools-dist/
		  setup.py
		  tstools/
#+end_example

The directory ~tstools-dist~ is a /distribution package/. We will later use this directory to... well, distribute our package ~tsools~.

*** EXERCICE: Installing ~tsools~ with pip
#+begin_exercise

- Write a new Python file ~setup.py~ in direcotry ~tstools-dist~ and write its minimal content.
- Add your email in the package metadata.
  Hint: A list of optional keywords for ~setuptools.setup~ can be found [[https://setuptools.readthedocs.io/en/latest/setuptools.html#new-and-changed-setup-keywords][here]].
- Install the ~tstools~ package with ~pip~.
  Remember: ~pip install <location of setup file>~
  Notice how ~numpy~ and ~matplotlib~ are automatically downloaded (can you find from where?)
  and installed.
- Move to the directory ~analysis2/~ and check that you can import your package from there.
  Where is this package located?
  Hint: You can check the location a package using the ~__file__~ attribute.
- The directory ~analysis2~ contains a timeseries under ~data/~. What is the average value
  of the timeseries?
#+end_exercise

** Maintaining your package indepently from the anaylises that use it
Congratulations! Your ~tstools~ package is now installed can be reused across your analyses...
no more hasardous copying and pasting!

However, the package is not set in stone and, as you work on your analysis, you will likely make changes to it.
For instance to add functionalities or to fix bugs.

You could just reinstall the package each time you make a modification to it.
This obviously can beome a bit tedious if you're trying many different things to fix a bug
and are constantly making changes and testing your package. In addition, you might forget
to update your package, leading to potentially very frustrating and time-consuming errors.

*** Editable installs
~pip~ has the ability to install the package in a so-called "editable" mode.
Instead of copying your package to the package installation location, pip will just
write a link to your package directory.
In this way, when importing your package, the python interpreter is redirected to
your package project directory.

To install your package in editable mode, use the ~-e~ option for the ~install~ command:
#+begin_src shell
pip install -e .
#+end_src

#+begin_exercise
1. Uninstall the package with src_shell{pip uninstall tstools}
2. List all the installed packages and check that ~tstools~ is not among them
   Hint: Use ~pip --help~ to get alist of available ~pip~ commands.
3. re-install ~tstools~ in editable mode.
4. Modify the ~tstools.vis.plot_trajectory_subset~ so that it returns the maximum value
   over the trajectory subset, in addition to the ~figure~ and ~axis~.
   Hint: You can use the numpy function ~amax~ to find the maximum of an array.
5. What is the maximum value of the timeseries in ~analysis1/data/timeseries1.csv~ between
   t=0 and t = 4 ?
#+end_exercise

In editable mode, ~pip install~ just write a file ~<package-name>.egg-link~ at the package
installation location in place of the actual package. This file contains the location of the
package in your package project directory:

#+begin_src shell
cat ~/python-workshop-venv/lib/python3.8/site-packages/tstools.egg-link
/home/thibault/org/data/6d/ac010a-3c1b-4b90-8fe2-67f782781a9e/tstools
#+end_src

** Summary and break
   - In order to reuse our package across different analyses, we must /install/ it.
     In effect, this means copying the package into a directory that is in the directory
     search path.
     This shouldn't be done manually, instead use the ~setuptools~ package to write
     ~setup.py~ file that is procesed by the ~pip install~ command.
   - It would be both cumbersome and error-prone to have to reinstall the package each time
     we make a change to it (to fix a bug for instance). Instead, the package can be installed
     in "editable" mode using the ~pip install -e~ command. This just redirects the python
     interpreter to your project directory.
   - The main value of packaging software is to faciliate its reuse across different projects.
     One you have extracted the right operations into a package that is independant of your
     analysis, you can easily "share" it between projects. In this way you avoid indefficient
     and dangerous duplicating of code.

Beyond greatly facilitating code reuse, writing a python package (as opposed to a loosely
organised collection of modules) enables a clear organisation of your software into modules
and possibly subpackages. It makes it much easier for others, as well as yourself, to
understand the structure of your software and who-does-what.

Moreover, organising your python software into a package gives you access to a myriad
of fantastic tools used by thousands of python developers everyday. Examples include
pytest for automated testing, sphinx for building you documentation, tox for automation
of project-level tasks.

* Intermezzo: Python virtual environments
** Problem: Installing different versions of a package
In the previous section you learned how to share a package across several projects, or analysis.
As your package and analyses evolve asynchronously, it is likely that you will readh a point when
you'd like differnet analyses to use different versions of your package, or any third-party
packages that your analysis rely on.

How to install two different versions of a same package?
The short answer is: you can't.

If you type ~pip install numpy==1.18~, ~pip~ first looks for a version
of ~numpy~ already installed (in the ~site-packages/~ directory).
If it finds a different version, say 1.19, ~pip~ will uninstall it and
install numpy 1.18 instead.

** Solution: virtual environments
Roughly speaking, the python executable ~/some_dir/lib/pythonX.Y/bin/python~
and the package installation location ~/some_dir/lib/pythonX.Y/site-packages/~
consitute what is commonly referred to your /python environment/.

If you cannot install different versions of a package in a single environment,
let's have multiple environments! This is the core idea of /python virtual environments/.
Whenever a python environment is /activated/, the ~python~ command points to a
python executable that is unique to this environment (~my-env/lib/pythonX.Y/bin/python~), with a unique package installation location
specific to this environment (~my_env/lib/pythonX.Y/site-packages~).

EXERCISE: Python virtualenvironmnes

1. Move to the ~analysis1/~ directory and create a virtual-environment there:
#+begin_src shell
python -m venv analysis1_venv
#+end_src
This commands creates a new directory ~analysis_venv~ in the current directory.
Feel free to explore its contents.

2. Activate the virtual envoronment for analysis1
#+begin_src shell
source analysis1_venv/bin/activate
#+end_src

3. What is the location of the current python executable?
   Hint: The built-in python package ~sys~ provides a variable ~executable~.

4. Use ~pip list~ to list the currently installed packages.
   Note that our package and its dependencies have disappeared, and only
   the core python packages are installed. We have a "fresh" python environment.

5. Move to the the ~tstools~ package prject directory and install it into the
current envirinment:
#+begin_src shell
pip install .
#+end_src

6. Where was the package installed?
   Hint: When importing package ~package~ in python, use ~package.__file__~
   to check the location of the corresponding ~__init__.py~ file.


The above exercise demonstrates that, after activating the ~analysis1_venv~, the command ~python~
executes the python executable ~ analysis1/analysis1_venv/bin/python~, and python packages are installed
in the ~analysis1/analysis1_venv/lib/pythonX.Y/site-packages~ directory.
This means that we are now working in a python environment that is /isolated/ from other python environments
in your machine:
- other virtual environments
- system python environment (see below)
- other versions of python installed in your system
- Anaconda environments

You can therefore install all the packages necesseray to your projects, without worry of breaking
other projects.

** Always use a virtual environment
You just learned what are python virtual environment and how to use them? Don't look back, and make them a habit.
The limitation that only one version of a package can be installed at one time in one python environment can be the source
of very frustrating problems, distracting you from your research.
Moreover, using one python environment for all your projects means that this environment will change as you work on different projects,
making it very hard to resolve dependency problems when they (and they will) occur.

Most of the time, a better approach is to have one (or more if needed) virtual envirornments per analyses and projects.
Coming back to our earlier example with the ~tstools~ package used in analysis analysis1 and analysis2, a recommnded setup
would be
#+begin_example
  tstools/
	  setup.py
	  tstools
	  venv_tstools
  (venv_tstools) $ pip install -e tstools/

  analysis1/
	  analysis1.py
	  data/
	  venv_analysis1/
  (venv_analysis1) $ pip install tstools/

  analysis2/
	  analysis2.py
	  data/
	  venv_analysis2/
  (venv_analysis2) $ pip install tstools/
#+end_example

When working on the package itself, we work within the virtual environment ~venv_tstools~, in
which the package is installed in editable mode. In this way, we avoid constant re-installation
of the package each time we make a change to it.

When working on either analyses, we activate the corresponding virtual environment, in which
our package ~tstools~ is installed in normal, non-editable mode, possibly along all the
other packages that we need for this particular analysis.

** Never use the system python
Most GNU/Linux distributions as well as MacOS come with a version of python already installed.
This version is often referred to as the /system python/ or the /base python/. *Leave it alone*.
As the name suggest, this version of python is used likely to be used by some parts of your system,
and updating or breaking it would mean breaking these partsof your system that rely on it.

Instead, you can install a more recent version of python by running, for instance
#+begin_src shell
apt install python3.8
#+end_src
 or
#+begin_src shell
brew install python3.8
#+end_src

and use it to create virtual environments for your projects:
#+begin_src shell
python3.8 -m venv my_venv
#+end_src

Once the virtual environment is activated, invoking the command ~python~ will start
the python 3.8 interpreter located in ~my_venv~.

*** TODO Installing utilities in global python 3.8
*** TODO managing several versions of pytho nwith pyenv


** Summary
- One big limitations of python is that only one version of a package can be installed in a given environment.
- virtual environments allow us to create multiple python environments, isolated from each other. Therefore we don't worry
  about breaking other projects that may rely on other versions of some packages.
- Having one virtual env per analysis is a good research practice since it faciliates reproducibility of your results.
- never use the system python installation, unless your have a very good reason to.

* Part 3 - Sharing the package
You now have a python package that you can use independently in your analyses.
This package lives somehwere in your system (the ~tstools/~) directory and your can install
it in a project's virtualenv using setuptools (~python setup.py install~).

We now look at ways your can /share/ your package with people interested in using your pkg.
This includes yourself.

Sharing means making it straightforward to both
- Obtain the source code
- Install and use the package

In practice this means that anyone will be able to "pip install" your package:
#+begin_src shell
pip install tstools
#+end_src

** Making tstools pip installable
*** Creating distributions
**** Building the distribution(s)
 The first is to generate a /distribution/ for the package, /i.e/ the ensemble of files and data
 necessary to both install and use the package.
 This usually takes the from of, or is akin to, an archive (~.tar~, ~.zip~).

 Make sure that you are in the ~tstools~ project root (where the ~setup.py~ is).
 #+begin_src python
 python setup.py sdist bdist_wheel
 #+end_src
 This builds *two* distribution:
 - A source distribution. It is a ~.tar~ archive containing the source (the ~.py~ files) and possibly the data required
   to use and/or test the package (/e.g/ parameters, input files, input data for tests...)
 - A wheel (or built distribution). In many cases this is very similar to the source distribution, but can present important advantages.

 We will discuss the difference between these twp distributions later.
 For now, suffice to remember that both are commonly generated together, and it is recommended
 to make both avaialable to users. Again, we'll understand why later.

 So where are these distributions? Notice that a directory ~lib/~ appeared next to the ~setup.py~
 #+begin_src shell
 ls lib/
 #+end_src

 #+NAME: install tstools with pip
 #+begin_exercise
 - Create a fresh virtualenv
 - Install tstools whith ~pip install tstools.wheelp~ (or ~pip install tstools.tar.gz~)
 #+end_exercise

**** Sharing the distribution: PyPI
 By generating the distribution(s) we bundled all the files and data required to install and use our package
 into a single file that can be very conviently installed through ~pip~.

 But we still need to make this file avaialbe to others.

 Python distributions can be freely hosted on Python Package Index (PyPI).
 Looking at numpy for instance, we can see all the available distribtions.

 When installing a python package as
 #+begin_src shell
 pip install numpy
 #+end_src
 by default ~pip~ makes a request to PyPI for the package ~numpy~ and downloads and install the
 relevant wheel.
 if no wheel availabe, it will download and install the ~sdist~.

 Let's see how to upload our tstools distributions to PyPI.

*** Uploading distributions to PyPI
 In this section we upload the source and wheel distribtuion created earlier to the test PyPI
 repository.
 For the purposes of this workshop, we actually make use of the test resposioty.
 It is a reposotory intended for tests only and there is no garantuee that your package will remain
 avaialbe on it over long duration. but it's the perfect tool to explore and learn.

 you will have to have an account on [[https://test.pypi.org/][test.pypi.org]] to continue.

 Uploading python distributions to TestPyPI (and PyPI) is made easy by a small python utility called [[https://pypi.org/project/twine/][twine]].

 First, within the ~tstools~ venv, install twine:
 #+begin_example
 $ (tstools) pip install twine
 #+end_example

 Then, upload the content of the ~lib/~ direcotry to TestPyPI

 #+begin_example
   $ (tstools) twine upload -i https://testpypi.org/simple lib/*
 #+end_example
 the switch ~-i https://testpypi.org/simple~ tells twine to upload the files to the test PyPI repo instead
 of the regular PyPI repo.

 #+NAME: Upload distributions and install tstools
 #+begin_exercise
 - In the tstools virtualenv, install twine and upload the distributions
 - Create a fresh virtualenv and install tstools from TestPyPI.
   Check the output of ~pip~ for the line(s) that show that the pacakge indeed comes from the TestPyPI index.

 Congratulations: you made your package pip installable !!
 #+end_exercise

* Part 4 - Going further
*** Source vs built distributions
*** Inlude data in the distribution
*** include tests in the distribution
*** Custom setuptools commands
*** Packaging C/C++/Fortran extensions
*** tox
