#+SEQ_TODO: TODO | DONE

* glossary
- package
- project
- analysis
- virtual environement
* Introduction
  What we are concerned about today: the problem(s) we want to solve.
  What we are going to do, the tools that we are going to use.
  The example that we are going to consider.

* Part 1 - Making a package
** Initial motivation: separating methods from parameters and data
A numerical experiment has three components:
- The data (dataset, or parameters of simulation)
- The operations performed on this data
- The output (numbers, plots)

At the moment parameters (input data), operations and output are intertwined in a single
python script.

This is often what we do in early exploratory phases, when the objective is to get insight
into data quickly. /Quickly/ means without having to think about software, /i.e/ taking the
shortest path to the scientific output (the plot).

However, this approach is (by design) messy.
Depsite short term convenience, putting data, operations and output in the same file is very
likely to slow down your research process on a longer term.

The main reason is code-reuse. Consider the situation where you have a similar timeseries,
and want to visualise its histogram. A straightfoward solution would be to copy and paste
lines 19 to 30 to the anaylis program for the new timeseries.
This approach is risky:
- If you want to modify this portion of code (fixing a bug, making improvements) you have to
  make sure you do across all the places where you duplicated the code.
- The duplicated code may not integrate itself well in another programm (conflicts in variable
names for example.
- Coding style discrepancies leading to poor readability.

Instead, we are going to separate the /operations/ from the data and output.
More precisely, we are going to implement the /operations/ on data inside a specific
/package/ that we trust and can reuse across many similar analyses.

The result could look like this:
#+begin_src python
  import numpy as np
  import matplotlib.pyplot as plt
  import my_pkg

  timeseries = np.genfromtxt("./data/my_timeseries.csv", delimiter=",")

  mean, var = my_pkg.get_mean_and_var(timeseries)

  fig, ax = my_pkg.get_pdf(timeseries)

  threshold = 3*np.sqrt(var)
  fig, ax = my_pkg.show_extremes(timeseries, threshold)
#+end_src

The above script is much shorter and easier to read, because the actual implementation of
the various operations (computing the mean and variance, computing the histogram...) is now
/encpsulated/ inside the package ~my_pkg~. All that remains are the actual steps of the
analysis.

If we were to make changes to the way some operations are implemented, we could simply make
changes to the package, leaving the scripts unmodified. The changes are then made avaialble
to all the programs that use the package: no more copying and pasting code around.

Conversely, by making change to the operations, you are a no risk of modyfing the analysis
itself (sequence of operations, data and parameters, output).

Taking a step back, the idea of separating different components is pervasive in software developemt
and software design. Different names depending on the field (encapsulation, separation of concerns,
bounded contexts...).

** Making a python package
*** The python hierachy: objects, modules, packages
- functions, classes
#+begin_src python
  # operations.py
  def add(a,b):
      return a+b
#+end_src
- modules
  Collection of python objects (classes, functions, variables)
#+begin_src python
  from operations import add
  # "From file (or module) operations.py import object add"

  result = add(1,2)
#+end_src
- packages
  Collection of modules (~.py~ files)
  #+begin_src python
    from calculator.operations import add
    from calculator.representations import hexa

    a = hexa(1)
    b = hexa(2)

    result = add(a,b)
  #+end_src

**** EXERCISE 1. Rewrite scripts into collection of functions
 Let's rewrite both scripts ~analyse_timeseries.py~ and ~show_extremes.py~
 as a collection of functions that can be reused in separate scripts.

 The directory ~tstools/~ contains 3 python modules that
 contain (incomplete) functions performing the operations on data described in the original scripts
 ~analysis_timeseries.py~ and ~show_extremes.py~

 1. Open ~tstools/moments.py~ and complete function ~get_mean_and_var~ (replace the
    string ~"######"~).
 2. Open file ~tstools/vis.py~ and complete functions ~plot_trajectory_subset~ and
    ~plot_histogram~ (replace the strings ~"######"~).

 File ~tstools/extremes.py~ implements a function ~show_extremes~ corresponding to script ~show_extremes.py~.
 It is already complete.
 So now it is technically possible to import each functions from the modules.
 But the script must be in this directory next to the modules.
 Plus we want to bundle both modules (and the ones to come) into a coherent
 ensemble: a /package/.

*** Let's make a package out of our 2 scripts
We now have a ~tstools~ directory with 3 modules:
#+begin_example
  workshop/
	  tstools/
	          __init__.py
		  moments.py
		  vis.py
		  show_extremes.py
	  data/
#+end_example

The file ~__init.py__~ (/underscore/ /underscore/ ~init~ /underscore/ /underscore/ ~.py~) is
just an empty file for now, and we will discuss it in the next section.

We can now import the functions defined in the ~tstools~ package's modules:
#+begin_src python
import tstools.moments
from tstools.vis import plot_histogram

timeseries = np.genfromtxt("../../data/brownian.csv", delimiter=",")

mean = tstools.moments.get_mean(timeseries)
fig, ax = tstools.moments.plot_histogram(timeseries)
#+end_src

Note that src_python{import tstools} doesn't actually import anything!

*** init dot pie
Our pacakge isn't very big, and the internal structure with 3 different modules isnt
very relevant for a user.
Say we would prefer to have the functions accessible at the top level, for instance

#+begin_src python
import tstools

timeseries = np.genfromtxt("../../data/brownian.csv", delimiter=",")

mean = tstools.get_mean(timeseries)
fig, ax = tstools.plot_histogram(timeseries)
#+end_src

To do this we can use a feature of the python interpreter called /package initialization/.

Remember that ~__init.py__~ file next to the modules? The content of this file can be
any valid python, that will be executed when the package or one of its submodule is
imported.

For instance, let's add a simple ~print~ statement to the ~__init__.py~ and import
function ~get_mean_and_var~ from module ~tstools.py~:
#+begin_src python
filename = __file__
print(f"Hello from {filename}")
#+end_src

#+begin_src python
  from tstools.tstools import get_mean_and_var
#+end_src

Any object (variable, function, class) defined in the ~__inint__.py~ file is available
under the paakge's namspace:

#+begin_src python
  import tstools
  print(tstools.filename)
#+end_src

#+begin_exercise
Write the ~__init__.py~ so that all functions defined in
modules ~tstools.py~ and ~show_extremes.py~ are accessible directly
at the top-lvel (under the ~tstools~ namespace), /i.e/

#+begin_src python
  import tstools
  meab, var = tstools.get_mean_and_var
  fig, ax = tstools.show_extremes(timeseries, 4*np.sqrt(var))
#+end_src

Hint: By default python looks for modules in the current directory
and some other locations (more about that later). When using ~import~,
you can refer to modules in the current package using the /dot notation/:
#+begin_src python
  # import something from module that resides
  # in the current package (next to the __init__.py)
  from .module import something
#+end_src

#+end_exercise

*** TODO Whats the value of any empty ~__init__.py~ ?
*** Note: objets defined in __init__.py are avaialbe when importing /the pacakge/
#+begin_src python
    # __init__.py
    mysymbol = "something"
    print(mysymbol)
#+end_src

#+begin_src python
  from tstools.tstools import get_mean_and_var
  # this prints "something" but mysymbol is not
  # accessible from tstools' namespace
#+end_src
* Part 2 - using the package across analyses
Now that we have a nice package, let's save us some time and reuse it.
the main value of having a package is to reuse it.

#+begin_example
  analysis2/
	  analysis2.py
#+end_example

#+begin_src python
  # analysis2.py
  import numpy as np
  import tstools

  timeseries = np.genfromtxt("./data/data.csv")
  fig, ax = tstools.plot_trajectory_subset(timeseries, 0, 50, dt=0.1)
#+end_src

*Problem* python cannot find the package!

** Where does python look for packages?
#+begin_example
>>> import sys
>>> sys.path
#+end_example

Lesson: python first looks inside the current dir, then inside the ~lib/pythonX.Y/site-packages~ dir.

Potential solutions:
- Copy pkg dir inside current analysis dir
- Add ~analysis1/pkg~ to ~sys.path~
- Copy ~pkg~ dir to ~site-packages~ dir
  Difficult to update?

None of these are generally recommended.
Recommended approach: use /setuptools/.

** setuptools and setup dot pie
/Installing/ a python package essentially means copying the package modules to a location
where they can be found by the python interpreter, usually the ~site-packages~ directory.

You could technically install your package by copying the package to the ~site-packages~
directory, /i.e/
#+begin_src shell
cp -r tstools venv/lib/pythonX.Y/site-packages/
#+end_src
however, this is not recommended for two main reasons:
- The installation location of python packages varies across systems (Windows, MacOS, various GNU/Linux distributions)
  and python environments. For instance, if you are using a didicated python environment for
your project (see below), you must make sure to install the package in the right location for this environment
and not for , for instane, the system's global python environment.
- It is likely that your python package will depend on other python packages. In our case,
  ~numpy~ and ~matplotlib~. You and your users will have to manually install them.

overall, manually installing packages would be error-prone and time consuming. Instead, we
can use the utility ~pip~ to /automatise/ this process.

*** setup dot pie
Installing a package with ~pip~ looks like this
#+begin_src shell
pip install <package directory>
#+end_src

let's give it a try
#+begin_src shell
pip install .
#+end_src

#+begin_example
Error because no setup.py
#+end_example

For ~pip~ to be able to install our package, we must first give it some information about it.
In fact ~pip~ expects to find a python file named ~setup.py~ in the directory that it is
given as an argument. This file is expected to call the function ~setup~
provided by the ~setuptools~ package (or the deprecated ~distutils~ package).

Here is a minimal ~setup.py~ file
#+begin_src python
  # In directory tstools-proj
  from setuptools import setup

  setup(name='tstools',
	version='0.1',
	description='A package to analyse timeseries',
	url='',
	author='Spam Eggs',
	author_email='spameggs@example.com',
	package=['tstools'],
	license='GPLv3')
#+end_src

The above gives ~pip~ some metadata about our package and, more importantly, the location
of the package to be install, in this case the directory ~tstools~.

Our package project directory now looks like this
#+begin_example
  tstools-proj/
	  setup.py
	  tstools/
		  ___init__.py
		  tstools.py
		  show_extremes.py
	  data/
#+end_example

*Piege* setup.py not located next to ~__init__.py~!!!


With that, let's install our package
#+begin_src shell
  pip install .
#+end_src

#+begin_exercise
- Write the ~setup.py~ for your own package and install your package using ~pip~.
  Notice how ~numpy~ and ~matplotlib~ are automatically downloaded (can you find from where?)
  and installed.
- Move to the directory ~analysis2/~ and check that you can import your package from there.
  Where is this package located?
  Hint: You can check the location a package using the ~__file__~ attribute.
- The directory ~analysis2~ contains a timeseries under ~data/~. What is the average value
  of the timeseries?
#+end_exercise

** Maintaining your package indepently from the anaylises that use it
Let's move the pkg out of analysis1/ and put it next to the two analyses that rely on it.

#+begin_example
  tstools
	  tstools/
		  base.py
		  show_extremes.py
  analysis1/
	  analysis1.py
	  data/
  analysis2/
	  analysis2.py
	  data/
#+end_example

We now have a package that can be reused across our analyses.
However, it is not set in stone and you will likely make changes to the package, for
instance to add functionalities or to fix bugs.

You could just reinstall the package each time you make a modification to it.
This obviously can beome a bit tedious if you're trying many different things to fix a bug
and are constantly making changes and testing your package. In addition, you might forget
to update your package, leading to potentially difficult errors.

*** Editable installs
~pip~ has the ability to install the package in a so-called "editable" mode.
Instead of copying your package to the package installation location, pip will just
write a link to your package directory.
In this way, when import ing your package, the python interpreter is redirected to
your package project directory.

To install your package in editable mode, use the ~-e~ option for the ~install~ command:
#+begin_src shell
pip install -e .
#+end_src

#+begin_exercise
1. Uninstall the package with src_shell{pip uninstall tstools}
2. List all the installed packages and check that ~tstools~ is not amoing them
   Hint: Use ~pip --help~ to get alist of available ~pip~ commands.
3. re-install ~tstools~ in editable mode.
4. Modify the ~tstools.tstools.plot_trajectory_subset~ so that it returns the maximum value
   over the trajectory subset.
   Hint: You can use the numpy function ~amax~ to find the maximum of an array.
5. What is the maximum value of the timeseries in ~analysis1/data/timeseries1.csv~ between
   t=0 and t = 4 ?
#+end_exercise

In editable mode, ~pip install~ just write a file ~<package-name>.egg-link~ at the package
installation location in place of the actuall package. This file contains the location of the
package in your package project directory:

#+begin_src shell
cat ~/venv/lib/python3.8/site-packages/tstools.egg-link
/home/thibault/org/data/6d/ac010a-3c1b-4b90-8fe2-67f782781a9e/tstools
#+end_src

** Summary and break
   - In order to reuse our package across different analyses, we must /install/ it.
     In effect, this means copying the package into a directory that is in the directory
     search path.
     This shouldn't be done manually, instead use the ~setuptools~ package to write
     ~setup.py~ file that is procesed by the ~pip install~ command.
   - It would be both cumbersome and error-prone to have to reinstall the package each time
     we make a change to it (to fix a bug for instance). Instead, the package can be installed
     in "editable" mode using the ~pip install -e~ command. This just redirects the python
     interpreter to your project directory.
   - The main value of packaging software is to faciliate its reuse across different projects.
     One you have extracted the right operations into a package that is independant of your
     analysis, you can easily "share" it between projects. In this way you avoid indefficient
     and dangerous duplicating of code.

Beyond greatly facilitating code reuse, writing a python package (as opposed to a loosely
organised collection of modules) enables a clear organisation of your software into modules
and possibly subpackages. It makes it much easier for others, as well as yourself, to
understand the structure of your software and who-does-what.

Moreover, organising your python software into a package gives you access to a myriad
of fantastic tools used by thousands of python developers everyday. Examples include
pytest for automated testing, sphinx for building you documentation, tox for automation
of project-level tasks.

* Intermezzo: Python virtual environments
** Problem: Installing different versions of a package
In the previous section you learned how to share a package across several projects, or analysis.
As your package and analyses evolve asynchronously, it is likely that you will readh a point when
you'd like differnet analyses to use different versions of your package, or any third-party
packages that your analysis rely on.

How to install two different versions of a same package?
The short answer is: you can't.

If you type ~pip install numpy==1.18~, ~pip~ first looks for a version
of ~numpy~ already installed (in the ~site-packages/~ directory).
If it finds a different version, say 1.19, ~pip~ will uninstall it and
install numpy 1.18 instead.

** Solution: virtual environments
Roughly speaking, the python executable ~/some_dir/lib/pythonX.Y/bin/python~
and the package installation location ~/some_dir/lib/pythonX.Y/site-packages/~
consitute what is commonly referred to your /python environment/.

If you cannot install different versions of a package in a single environment,
let's have multiple environments! This is the core idea of /python virtual environments/.
Whenever a python environment is /activated/, the ~python~ command points to a
python executable that is unique to this environment (~my-env/lib/pythonX.Y/bin/python~), with a unique package installation location
specific to this environment (~my_env/lib/pythonX.Y/site-packages~).

EXERCISE: Python virtualenvironmnes

1. Move to the ~analysis1/~ directory and create a virtual-environment there:
#+begin_src shell
python -m venv analysis1_venv
#+end_src
This commands creates a new directory ~analysis_venv~ in the current directory.
Feel free to explore its contents.

2. Activate the virtual envoronment for analysis1
#+begin_src shell
source analysis1_venv/bin/activate
#+end_src

3. What is the location of the current python executable?
   Hint: The built-in python package ~sys~ provides a variable ~executable~.

4. Use ~pip list~ to list the currently installed packages.
   Note that our package and its dependencies have disappeared, and only
   the core python packages are installed. We have a "fresh" python environment.

5. Move to the the ~tstools~ package prject directory and install it into the
current envirinment:
#+begin_src shell
pip install .
#+end_src

6. Where was the package installed?
   Hint: When importing package ~package~ in python, use ~package.__file__~
   to check the location of the corresponding ~__init__.py~ file.


The above exercise demonstrates that, after activating the ~analysis1_venv~, the command ~python~
executes the python executable ~ analysis1/analysis1_venv/bin/python~, and python packages are installed
in the ~analysis1/analysis1_venv/lib/pythonX.Y/site-packages~ directory.
This means that we are now working in a python environment that is /isolated/ from other python environments
in your machine:
- other virtual environments
- system python environment (see below)
- other versions of python installed in your system
- Anaconda environments

You can therefore install all the packages necesseray to your projects, without worry of breaking
other projects.

** Always use a virtual environment
You just learned what are python virtual environment and how to use them? Don't look back, and make them a habit.
The limitation that only one version of a package can be installed at one time in one python environment can be the source
of very frustrating problems, distracting you from your research.
Moreover, using one python environment for all your projects means that this environment will change as you work on different projects,
making it very hard to resolve dependency problems when they (and they will) occur.

Most of the time, a better approach is to have one (or more if needed) virtual envirornments per analyses and projects.
Coming back to our earlier example with the ~tstools~ package used in analysis analysis1 and analysis2, a recommnded setup
would be
#+begin_example
  tstools/
	  setup.py
	  tstools
	  venv_tstools
  (venv_tstools) $ pip install -e tstools/

  analysis1/
	  analysis1.py
	  data/
	  venv_analysis1/
  (venv_analysis1) $ pip install tstools/

  analysis2/
	  analysis2.py
	  data/
	  venv_analysis2/
  (venv_analysis2) $ pip install tstools/
#+end_example

When working on the package itself, we work within the virtual environment ~venv_tstools~, in
which the package is installed in editable mode. In this way, we avoid constant re-installation
of the package each time we make a change to it.

When working on either analyses, we activate the corresponding virtual environment, in which
our package ~tstools~ is installed in normal, non-editable mode, possibly along all the
other packages that we need for this particular analysis.

** Never use the system python
Most GNU/Linux distributions as well as MacOS come with a version of python already installed.
This version is often referred to as the /system python/ or the /base python/. *Leave it alone*.
As the name suggest, this version of python is used likely to be used by some parts of your system,
and updating or breaking it would mean breaking these partsof your system that rely on it.

Instead, you can install a more recent version of python by running, for instance
#+begin_src shell
apt install python3.8
#+end_src
 or
#+begin_src shell
brew install python3.8
#+end_src

and use it to create virtual environments for your projects:
#+begin_src shell
python3.8 -m venv my_venv
#+end_src

Once the virtual environment is activated, invoking the command ~python~ will start
the python 3.8 interpreter located in ~my_venv~.

*** TODO Installing utilities in global python 3.8
*** TODO managing several versions of pytho nwith pyenv


** Summary
- One big limitations of python is that only one version of a package can be installed in a given environment.
- virtual environments allow us to create multiple python environments, isolated from each other. Therefore we don't worry
  about breaking other projects that may rely on other versions of some packages.
- Having one virtual env per analysis is a good research practice since it faciliates reproducibility of your results.
- never use the system python installation, unless your have a very good reason to.

* Part 3 - Sharing the package
You now have a python package that you can use independently in your analyses.
This package lives somehwere in your system (the ~tstools/~) directory and your can install
it in a project's virtualenv using setuptools (~python setup.py install~).

We now look at ways your can /share/ your package with people interested in using your pkg.
This includes yourself.

Sharing means making it straightforward to both
- Obtain the source code
- Install and use the package

In practice this means that anyone will be able to "pip install" your package:
#+begin_src shell
pip install tstools
#+end_src

** Making tstools pip installable
*** Creating distributions
**** Building the distribution(s)
 The first is to generate a /distribution/ for the package, /i.e/ the ensemble of files and data
 necessary to both install and use the package.
 This usually takes the from of, or is akin to, an archive (~.tar~, ~.zip~).

 Make sure that you are in the ~tstools~ project root (where the ~setup.py~ is).
 #+begin_src python
 python setup.py sdist bdist_wheel
 #+end_src
 This builds *two* distribution:
 - A source distribution. It is a ~.tar~ archive containing the source (the ~.py~ files) and possibly the data required
   to use and/or test the package (/e.g/ parameters, input files, input data for tests...)
 - A wheel (or built distribution). In many cases this is very similar to the source distribution, but can present important advantages.

 We will discuss the difference between these twp distributions later.
 For now, suffice to remember that both are commonly generated together, and it is recommended
 to make both avaialable to users. Again, we'll understand why later.

 So where are these distributions? Notice that a directory ~lib/~ appeared next to the ~setup.py~
 #+begin_src shell
 ls lib/
 #+end_src

 #+NAME: install tstools with pip
 #+begin_exercise
 - Create a fresh virtualenv
 - Install tstools whith ~pip install tstools.wheelp~ (or ~pip install tstools.tar.gz~)
 #+end_exercise

**** Sharing the distribution: PyPI
 By generating the distribution(s) we bundled all the files and data required to install and use our package
 into a single file that can be very conviently installed through ~pip~.

 But we still need to make this file avaialbe to others.

 Python distributions can be freely hosted on Python Package Index (PyPI).
 Looking at numpy for instance, we can see all the available distribtions.

 When installing a python package as
 #+begin_src shell
 pip install numpy
 #+end_src
 by default ~pip~ makes a request to PyPI for the package ~numpy~ and downloads and install the
 relevant wheel.
 if no wheel availabe, it will download and install the ~sdist~.

 Let's see how to upload our tstools distributions to PyPI.

*** Uploading distributions to PyPI
 In this section we upload the source and wheel distribtuion created earlier to the test PyPI
 repository.
 For the purposes of this workshop, we actually make use of the test resposioty.
 It is a reposotory intended for tests only and there is no garantuee that your package will remain
 avaialbe on it over long duration. but it's the perfect tool to explore and learn.

 you will have to have an account on [[https://test.pypi.org/][test.pypi.org]] to continue.

 Uploading python distributions to TestPyPI (and PyPI) is made easy by a small python utility called [[https://pypi.org/project/twine/][twine]].

 First, within the ~tstools~ venv, install twine:
 #+begin_example
 $ (tstools) pip install twine
 #+end_example

 Then, upload the content of the ~lib/~ direcotry to TestPyPI

 #+begin_example
   $ (tstools) twine upload -i https://testpypi.org/simple lib/*
 #+end_example
 the switch ~-i https://testpypi.org/simple~ tells twine to upload the files to the test PyPI repo instead
 of the regular PyPI repo.

 #+NAME: Upload distributions and install tstools
 #+begin_exercise
 - In the tstools virtualenv, install twine and upload the distributions
 - Create a fresh virtualenv and install tstools from TestPyPI.
   Check the output of ~pip~ for the line(s) that show that the pacakge indeed comes from the TestPyPI index.

 Congratulations: you made your package pip installable !!
 #+end_exercise

* Part 4 - Going further
*** Source vs built distributions
*** Inlude data in the distribution
*** include tests in the distribution
*** Custom setuptools commands
*** Packaging C/C++/Fortran extensions
*** tox
